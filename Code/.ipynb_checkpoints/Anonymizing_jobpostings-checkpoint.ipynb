{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-04-09 08:46:45 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2021-04-09 08:46:45 INFO: Use device: cpu\n",
      "2021-04-09 08:46:45 INFO: Loading: tokenize\n",
      "2021-04-09 08:46:45 INFO: Loading: ner\n",
      "2021-04-09 08:46:46 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from flashtext import KeywordProcessor\n",
    "#import spacy\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#for downloading spacy stuff\n",
    "#!{sys.executable} -m spacy download en_core_web_sm\n",
    "\n",
    "#nlp = spacy.load(\"en_core_web_lg\")\n",
    "\n",
    "import stanza\n",
    "\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,ner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "def name_remover(text):\n",
    "    \n",
    "    try:\n",
    "        doc = nlp(text)\n",
    "\n",
    "        sentences =[]\n",
    "        for sentence in doc.sentences:\n",
    "            for token in sentence.tokens:\n",
    "                #Removing all tokens which have been tagged as PERSON\n",
    "                if 'PERSON' not in token.ner:\n",
    "                    sentences.append(token.text)\n",
    "            #Adding new line symbol after each sentence to clearly denote the end of the sentence\n",
    "            sentences.append('\\n')\n",
    "        listToStr = ' '.join([str(elem) for elem in sentences]) \n",
    "        return listToStr\n",
    "    except:\n",
    "        #Catching any errors and storing those values in errors\n",
    "        print('error_found')\n",
    "        errors.append(text)\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 17880/17880 [00:10<00:00, 1737.12it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 17880/17880 [00:07<00:00, 2297.02it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Food52, a fast-growing, James Beard Award-winning online food community and crowd-sourced and curated recipe hub, is currently interviewing full- and part-time unpaid interns to work in a small team of editors, executives, and developers in its New York City headquarters.\\n\\nReproducing and/or repackaging existing Food52 content for a number of partner sites, such as Huffington Post, Yahoo, Buzzfeed, and more in their various content management systems\\nResearching blogs and websites for the Provisions by Food52 Affiliate Program\\nAssisting in day-to-day affiliate program support, such as screening affiliates and assisting in any affiliate inquiries\\nSupporting with PR & Events when needed\\nHelping with office administrative work, such as filing, mailing, and preparing for meetings\\nWorking with developers to document bugs and suggest improvements to the site\\nSupporting the marketing and executive staff\\n \\nExperience with content management systems a major plus (any blogging counts!)\\nFamiliar with the Food52 editorial voice and aesthetic\\nLoves food, appreciates the importance of home cooking and cooking with the seasons\\nMeticulous editor, perfectionist, obsessive attention to detail, maddened by typos and broken links, delighted by finding and fixing them\\nCheerful under pressure\\nExcellent communication skills\\nA+ multi-tasker and juggler of responsibilities big and small\\nInterested in and engaged with social media like Twitter, Facebook, and Pinterest\\nLoves problem-solving and collaborating to drive Food52 forward\\nThinks big picture but pitches in on the nitty gritty of running a small company (dishes, shopping, administrative support)\\nComfortable with the realities of working for a startup: being on call on evenings and weekends, and working long hours\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"D:\\Sync\\Thesis\\Datasources\\Job vacancies\\emscad_v1 2.csv\")\n",
    "\n",
    "#Removing the html tags in the columns.\n",
    "rows = []\n",
    "for t in tqdm(df['description']):\n",
    "    soup = BeautifulSoup(t,\"lxml\")\n",
    "    rows.append(soup.get_text())\n",
    "df['description'] = rows\n",
    "\n",
    "rows = []\n",
    "#Some columns contain nan therefore appending no text\n",
    "for t in tqdm(df['requirements']):\n",
    "    if str(t) == 'nan':\n",
    "        rows.append('')\n",
    "    else:\n",
    "        soup = BeautifulSoup(t,\"lxml\")\n",
    "        rows.append(soup.get_text())\n",
    "df['requirements'] = rows\n",
    "\n",
    "df['job_description'] = df['description'] + ' ' + df['requirements']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                             | 20/17880 [00:52<9:19:45,  1.88s/it]"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "#df_2 = df_2.head(100)\n",
    "df['job_description'] = df['job_description'].progress_apply(name_remover)\n",
    "df['job_description'].iloc[0]\n",
    "df.to_csv(\"D:/Sync/Thesis/Datasources/Job vacancies/emscad_v1_anonymized.csv\", index=False)\n",
    "#df_1 = 0\n",
    "#df_2['job_description'] = df_2['job_description'].progress_apply(name_remover)\n",
    "#df_2.to_csv(\"/Users/ivowings/Sync/Thesis/Datasources/Preprocessed/jobpostings_anonymized_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install stanza  --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(errors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
