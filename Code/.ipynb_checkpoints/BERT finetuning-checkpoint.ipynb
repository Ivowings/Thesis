{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "requested-authority",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.adam import Adam\n",
    "\n",
    "from flair.data import Corpus\n",
    "from flair.datasets import TREC_6\n",
    "from flair.embeddings import TransformerDocumentEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arbitrary-fraud",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.datasets import ClassificationCorpus\n",
    "\n",
    "# this is the folder in which train, test and dev files reside\n",
    "data_folder = '/Users/ivowings/Sync/Thesis/Datasources/Preprocessed/Skills/Pre annotated soft skills/annotated_soft_skills_context.csv'\n",
    "\n",
    "# load corpus containing training, test and dev data\n",
    "corpus: Corpus = ClassificationCorpus(data_folder,\n",
    "                                      test_file='test.txt',\n",
    "                                      dev_file='dev.txt',\n",
    "                                      train_file='train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "documentary-broadcast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-11 10:46:02,770 https://cogcomp.seas.upenn.edu/Data/QA/QC/train_5500.label not found in cache, downloading to /var/folders/q2/19lfg4cx24g87g50tyc3xn9c0000gn/T/tmpxwis_tce\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 335858/335858 [00:01<00:00, 304608.22B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-11 10:46:05,327 copying /var/folders/q2/19lfg4cx24g87g50tyc3xn9c0000gn/T/tmpxwis_tce to cache at /Users/ivowings/.flair/datasets/trec_6/original/train_5500.label\n",
      "2021-05-11 10:46:05,333 removing temp file /var/folders/q2/19lfg4cx24g87g50tyc3xn9c0000gn/T/tmpxwis_tce\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-11 10:46:05,840 https://cogcomp.seas.upenn.edu/Data/QA/QC/TREC_10.label not found in cache, downloading to /var/folders/q2/19lfg4cx24g87g50tyc3xn9c0000gn/T/tmpm9pny1__\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23354/23354 [00:00<00:00, 187875.14B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-11 10:46:06,302 copying /var/folders/q2/19lfg4cx24g87g50tyc3xn9c0000gn/T/tmpm9pny1__ to cache at /Users/ivowings/.flair/datasets/trec_6/original/TREC_10.label\n",
      "2021-05-11 10:46:06,305 removing temp file /var/folders/q2/19lfg4cx24g87g50tyc3xn9c0000gn/T/tmpm9pny1__\n",
      "2021-05-11 10:46:06,346 Reading data from /Users/ivowings/.flair/datasets/trec_6\n",
      "2021-05-11 10:46:06,346 Train: /Users/ivowings/.flair/datasets/trec_6/train.txt\n",
      "2021-05-11 10:46:06,347 Dev: None\n",
      "2021-05-11 10:46:06,348 Test: /Users/ivowings/.flair/datasets/trec_6/test.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. get the corpus\n",
    "corpus: Corpus = TREC_6()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "reasonable-explanation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-11 10:47:46,105 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5407/5407 [00:00<00:00, 30405.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-11 10:47:46,286 [b'DESC', b'ENTY', b'ABBR', b'HUM', b'NUM', b'LOC']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. create the label dictionary\n",
    "label_dict = corpus.make_label_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "approximate-magnitude",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c8441111446445ca935eab80fd0124d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/442 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdf189dfbebd464295f1c4164694888c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. initialize transformer document embeddings (many models are available)\n",
    "document_embeddings = TransformerDocumentEmbeddings('distilbert-base-uncased', fine_tune=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "thousand-southeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. create the text classifier\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "starting-secretariat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. initialize the text classifier trainer with Adam optimizer\n",
    "trainer = ModelTrainer(classifier, corpus, optimizer=Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heard-chinese",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-05-11 10:48:16,445 ----------------------------------------------------------------------------------------------------\n",
      "2021-05-11 10:48:16,448 Model: \"TextClassifier(\n",
      "  (document_embeddings): TransformerDocumentEmbeddings(\n",
      "    (model): DistilBertModel(\n",
      "      (embeddings): Embeddings(\n",
      "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (transformer): Transformer(\n",
      "        (layer): ModuleList(\n",
      "          (0): TransformerBlock(\n",
      "            (attention): MultiHeadSelfAttention(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            )\n",
      "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (1): TransformerBlock(\n",
      "            (attention): MultiHeadSelfAttention(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            )\n",
      "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (2): TransformerBlock(\n",
      "            (attention): MultiHeadSelfAttention(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            )\n",
      "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (3): TransformerBlock(\n",
      "            (attention): MultiHeadSelfAttention(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            )\n",
      "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (4): TransformerBlock(\n",
      "            (attention): MultiHeadSelfAttention(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            )\n",
      "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "          (5): TransformerBlock(\n",
      "            (attention): MultiHeadSelfAttention(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            )\n",
      "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (ffn): FFN(\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            )\n",
      "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Linear(in_features=768, out_features=6, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (beta): 1.0\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2021-05-11 10:48:16,451 ----------------------------------------------------------------------------------------------------\n",
      "2021-05-11 10:48:16,464 Corpus: \"Corpus: 4907 train + 545 dev + 500 test sentences\"\n",
      "2021-05-11 10:48:16,480 ----------------------------------------------------------------------------------------------------\n",
      "2021-05-11 10:48:16,490 Parameters:\n",
      "2021-05-11 10:48:16,504  - learning_rate: \"3e-05\"\n",
      "2021-05-11 10:48:16,505  - mini_batch_size: \"16\"\n",
      "2021-05-11 10:48:16,507  - patience: \"3\"\n",
      "2021-05-11 10:48:16,508  - anneal_factor: \"0.5\"\n",
      "2021-05-11 10:48:16,512  - max_epochs: \"5\"\n",
      "2021-05-11 10:48:16,514  - shuffle: \"True\"\n",
      "2021-05-11 10:48:16,516  - train_with_dev: \"False\"\n",
      "2021-05-11 10:48:16,517  - batch_growth_annealing: \"False\"\n",
      "2021-05-11 10:48:16,520 ----------------------------------------------------------------------------------------------------\n",
      "2021-05-11 10:48:16,522 Model training base path: \"resources/taggers/trec\"\n",
      "2021-05-11 10:48:16,524 ----------------------------------------------------------------------------------------------------\n",
      "2021-05-11 10:48:16,525 Device: cpu\n",
      "2021-05-11 10:48:16,526 ----------------------------------------------------------------------------------------------------\n",
      "2021-05-11 10:48:16,528 Embeddings storage mode: cpu\n",
      "2021-05-11 10:48:16,546 ----------------------------------------------------------------------------------------------------\n",
      "2021-05-11 10:50:20,157 ----------------------------------------------------------------------------------------------------\n",
      "2021-05-11 10:50:20,158 Exiting from training early.\n",
      "2021-05-11 10:50:20,159 Saving model ...\n",
      "2021-05-11 10:50:20,820 Done.\n",
      "2021-05-11 10:50:20,821 ----------------------------------------------------------------------------------------------------\n",
      "2021-05-11 10:50:20,822 Testing using best model ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 6. start the training\n",
    "trainer.train('resources/taggers/trec',\n",
    "              learning_rate=3e-5, # use very small learning rate\n",
    "              mini_batch_size=16,\n",
    "              mini_batch_chunk_size=4, # optionally set this if transformer is too much for your machine\n",
    "              max_epochs=5, # terminate after 5 epochs\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monetary-neighborhood",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
