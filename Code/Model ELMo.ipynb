{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U pip setuptools wheel\n",
    "# pip install -U spacy\n",
    "# python -m spacy download en_core_web_sm\n",
    "# pip install allennlp==0.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install allennlp==0.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import thesis_helper\n",
    "functions = thesis_helper.Thesis_Helper()\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from flair.data import Sentence\n",
    "\n",
    "from flair.embeddings import ELMoEmbeddings\n",
    "\n",
    "# init embedding\n",
    "embedding = ELMoEmbeddings('small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = '/Users/ivowings/Sync/Thesis/Datasources/Preprocessed/Combined/Taxonomy/Normal/Annotated/combined_annotations.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of annotated rows  20740\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(annotations,sep=';')\n",
    "\n",
    "#Filling any empty context columns with 'empty'\n",
    "df['left_context'] = df['left_context'].fillna('empty')\n",
    "df['right_context'] = df['right_context'].fillna('empty')\n",
    "\n",
    "df['concatenated'] = df['left_context'] + ' | ' + df['candidate_skill'] + ' | ' + df['right_context']\n",
    "print('Number of annotated rows ',df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 token has 1536 columns\n",
    "# there are more than 3 tokens\n",
    "def ELMo_embedder(text):\n",
    "\n",
    "    string = Sentence(text)\n",
    "    embedding.embed(string)\n",
    "\n",
    "    # Creating a list which stores the indexes of the | symbols\n",
    "    bar_indexes = []\n",
    "    #Creating a list which stores the embedding_tensors\n",
    "    embedding_tensors = []\n",
    "\n",
    "    #Checking the sentence object for the | symbols and storing their indexes\n",
    "    for x in range(1,len(string)+1):\n",
    "        if '|' in str(string.get_token(x)):\n",
    "            bar_indexes.append(x)\n",
    "\n",
    "    #Collecting the embeddings for every index between the indexes in bar_indexes\n",
    "    word_embedding_indexes = range(bar_indexes[0]+1,bar_indexes[1])\n",
    "    for x in word_embedding_indexes:\n",
    "        embedding_tensors.append(pd.Series(string[x].embedding))\n",
    "        embedding_tensors.append(222)\n",
    "\n",
    "    #Removing last 666 from list\n",
    "    embedding_tensors.pop()\n",
    "\n",
    "    #Turning the elements from embedding_tensors into dataframe rows\n",
    "    row = pd.DataFrame()\n",
    "    for x in range(0,len(embedding_tensors)):\n",
    "        row = row.append(pd.DataFrame(pd.Series(embedding_tensors[x])))\n",
    "\n",
    "    row = row.transpose().reset_index(drop=True)\n",
    "    \n",
    "    #Changing the column names in order to make pd.concat work later\n",
    "    row.columns = [x for x in range(0,len(row.columns))]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['embeddings'] = df['concatenated'].progress_apply(ELMo_embedder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_elmo = pd.concat(df['embeddings'].tolist()).reset_index(drop=True)\n",
    "x_elmo = x_elmo.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle_out = open(('x_elmo'+\".pickle\"),\"wb\")\n",
    "pickle.dump(x_elmo, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "import pickle\n",
    "pickle_out = open(('y_elmo'+\".pickle\"),\"wb\")\n",
    "pickle.dump(df['label'], pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_elmo = functions.load_object('x_elmo')\n",
    "y_elmo = functions.load_object('y_elmo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# clf = LogisticRegression(solver='liblinear', max_iter=100000000000000000,random_state=123)#.fit(x_elmo, y_elmo)\n",
    "# #clf.score(x_elmo, y_elmo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# #2 folds took 23 minutes with lbfgs solver\n",
    "# #default took 19 min\n",
    "# #liblinear took \n",
    "# solvers = ['sag', 'saga', 'lbfgs', 'liblinear', 'newton-cg']\n",
    "\n",
    "# from sklearn.model_selection import cross_validate\n",
    "# from statistics import mean\n",
    "# performance_measures = ['precision_macro', 'recall_macro','f1_macro']\n",
    "# scores = cross_validate(clf, x_elmo, y_elmo, scoring=performance_measures,cv=2,verbose=1,n_jobs=-1)#n_jobs=0, verbose=1)\n",
    "\n",
    "# average_precision = mean(scores['test_precision_macro'])\n",
    "# average_recall = mean(scores['test_recall_macro'])\n",
    "# average_f1 = mean(scores['test_f1_macro'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores['test_precision_macro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model evaluation\n",
      "We are at classifier  LogisticRegression(max_iter=10000000000000000000000, random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 159.5min finished\n",
      " 17%|█▋        | 1/6 [2:39:31<13:17:36, 9571.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  GradientBoostingClassifier(learning_rate=1.0, max_depth=1, random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 48.6min finished\n",
      " 33%|███▎      | 2/6 [3:28:06<6:17:02, 5655.66s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  SGDClassifier(max_iter=10000000000000000000000, random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   10.1s finished\n",
      " 50%|█████     | 3/6 [3:28:16<2:33:53, 3077.80s/it][Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  RandomForestClassifier(random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  3.9min finished\n",
      " 67%|██████▋   | 4/6 [3:32:09<1:05:09, 1954.89s/it][Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  SVC(decision_function_shape='ovo', random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 32.4min finished\n",
      "\r",
      " 83%|████████▎ | 5/6 [4:04:32<32:30, 1950.73s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  MLPClassifier(alpha=1e-05, hidden_layer_sizes=(15,),\n",
      "              max_iter=10000000000000000000000, random_state=456,\n",
      "              solver='lbfgs')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 213.9min finished\n",
      "100%|██████████| 6/6 [7:38:26<00:00, 4584.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.9 s, sys: 3.02 s, total: 4.92 s\n",
      "Wall time: 7h 38min 26s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.761868</td>\n",
       "      <td>0.727245</td>\n",
       "      <td>0.730439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GBC</td>\n",
       "      <td>0.736234</td>\n",
       "      <td>0.614475</td>\n",
       "      <td>0.642147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.882080</td>\n",
       "      <td>0.579037</td>\n",
       "      <td>0.624879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.534333</td>\n",
       "      <td>0.426132</td>\n",
       "      <td>0.437950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.715426</td>\n",
       "      <td>0.721307</td>\n",
       "      <td>0.707554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier  Precision    Recall        F1\n",
       "0         LR   0.761868  0.727245  0.730439\n",
       "1        GBC   0.736234  0.614475  0.642147\n",
       "2        SGD        NaN       NaN       NaN\n",
       "3         RF   0.882080  0.579037  0.624879\n",
       "4        SVM   0.534333  0.426132  0.437950\n",
       "5        MLP   0.715426  0.721307  0.707554"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "functions.model_performance(x_elmo, y_elmo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20740/20740 [01:53<00:00, 183.36it/s]\n",
      "100%|██████████| 20740/20740 [01:52<00:00, 183.57it/s]\n",
      "100%|██████████| 20740/20740 [01:52<00:00, 184.47it/s]\n",
      "100%|██████████| 20740/20740 [01:52<00:00, 184.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3134\n"
     ]
    }
   ],
   "source": [
    "df['pos'] = df['candidate_skill'].progress_apply(functions.pos_tagger)\n",
    "df['pos'] = df['pos'].progress_apply(functions.sequence_counter)\n",
    "\n",
    "pos_dicts = df[['pos']]\n",
    "pos_dicts = pos_dicts['pos'].apply(pd.Series)\n",
    "pos_dicts = pos_dicts.fillna(0).astype(int)\n",
    "\n",
    "df['dep'] = df['candidate_skill'].progress_apply(functions.dep_tagger)\n",
    "df['dep'] = df['dep'].progress_apply(functions.sequence_counter)\n",
    "\n",
    "dep_dicts = df[['dep']]\n",
    "dep_dicts = dep_dicts['dep'].apply(pd.Series)\n",
    "dep_dicts = dep_dicts.fillna(0).astype(int)\n",
    "\n",
    "x_pos = pos_dicts.join(dep_dicts,lsuffix='_gram', rsuffix='_pos')\n",
    "\n",
    "x = x_elmo.join(x_pos, lsuffix='_embedding', rsuffix='_pos')\n",
    "print(x.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model evaluation\n",
      "We are at classifier  LogisticRegression(max_iter=10000000000000000000000, random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 148.8min finished\n",
      " 17%|█▋        | 1/6 [2:28:45<12:23:49, 8925.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  GradientBoostingClassifier(learning_rate=1.0, max_depth=1, random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 47.9min finished\n",
      " 33%|███▎      | 2/6 [3:16:38<5:57:41, 5365.31s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  SGDClassifier(max_iter=10000000000000000000000, random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   10.8s finished\n",
      " 50%|█████     | 3/6 [3:16:49<2:26:01, 2920.39s/it][Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  RandomForestClassifier(random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  3.8min finished\n",
      " 67%|██████▋   | 4/6 [3:20:35<1:01:53, 1856.68s/it][Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  SVC(decision_function_shape='ovo', random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 32.5min finished\n",
      "\r",
      " 83%|████████▎ | 5/6 [3:53:03<31:29, 1889.58s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  MLPClassifier(alpha=1e-05, hidden_layer_sizes=(15,),\n",
      "              max_iter=10000000000000000000000, random_state=456,\n",
      "              solver='lbfgs')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 711.0min finished\n",
      "100%|██████████| 6/6 [15:44:04<00:00, 9440.83s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.2 s, sys: 2.65 s, total: 4.84 s\n",
      "Wall time: 15h 44min 5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.764356</td>\n",
       "      <td>0.728036</td>\n",
       "      <td>0.731294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GBC</td>\n",
       "      <td>0.738347</td>\n",
       "      <td>0.634522</td>\n",
       "      <td>0.664286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.878428</td>\n",
       "      <td>0.576704</td>\n",
       "      <td>0.620804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.534181</td>\n",
       "      <td>0.426250</td>\n",
       "      <td>0.438054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.707254</td>\n",
       "      <td>0.710939</td>\n",
       "      <td>0.699292</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier  Precision    Recall        F1\n",
       "0         LR   0.764356  0.728036  0.731294\n",
       "1        GBC   0.738347  0.634522  0.664286\n",
       "2        SGD        NaN       NaN       NaN\n",
       "3         RF   0.878428  0.576704  0.620804\n",
       "4        SVM   0.534181  0.426250  0.438054\n",
       "5        MLP   0.707254  0.710939  0.699292"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "functions.model_performance(x.fillna(0), y_elmo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[x.isna().any(axis=1)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions.print(df.concatenated.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions.print(x.iloc[188])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "functions.model_performance(x, df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions.confusion_matrix(functions.LR,x.fillna(0), df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.drop(columns=['label']), df['label'], test_size=0.20, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "#y_test['predictions'] = functions.LR.fit(X_train.fillna(0),y_train).predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat(X_train['test'].tolist()).reset_index(drop=True)\n",
    "X_train = X_train.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.concat(X_test['test'].tolist()).reset_index(drop=True)\n",
    "X_test = X_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test['predictions'] = functions.LR.fit(X_train,y_train).predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train['type'] = 'train'\n",
    "y_test['type'] = 'test'\n",
    "\n",
    "y = pd.concat([y_train,y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.join(y_test,lsuffix='_echt', rsuffix='_pred')\n",
    "test = test[['left_context','recovered_gram', 'right_context', 'label_echt', 'label_pred']]\n",
    "test.to_csv('/Users/ivowings/Desktop/test1000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = df[['left_context', 'recovered_gram', 'right_context', 'label', 'predictions']]\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance[(performance.label==0) & (performance.predictions==1)].to_csv('/Users/ivowings/Desktop/test5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = [1379411,\n",
    "2837,\n",
    "6853,\n",
    "5332,\n",
    "1379216,\n",
    "          6161,6921]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "performance = performance.loc[indexes] \n",
    "#performance = performance.rename(columns={'focus_words':'candidate_skill'})\n",
    "\n",
    "\n",
    "performance = performance.replace(0,'not skill')\n",
    "performance = performance.replace(1,'soft skill')\n",
    "performance = performance.replace(2,'hard skill')\n",
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataframe_image as dfi\n",
    "dfi.export(performance,\"Predictions.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = performance.loc[indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.replace(0,'not skill')\n",
    "predictions = predictions.replace(1,'soft skill')\n",
    "predictions = predictions.replace(2,'hard skill')\n",
    "predictions = predictions.rename(columns={'label': 'actual_label', 'predictions':'classifier_prediction'})\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
