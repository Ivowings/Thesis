{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "import thesis_helper\n",
    "functions = thesis_helper.Thesis_Helper()\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "word2vec = api.load(\"glove-wiki-gigaword-300\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations = '/Users/ivowings/Sync/Thesis/Datasources/Preprocessed/Combined/Taxonomy/Normal/Annotated/combined_annotations.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of annotated rows  20740\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(annotations,sep=';')\n",
    "\n",
    "#Filling any empty context columns with 'empty'\n",
    "df['left_context'] = df['left_context'].fillna('empty')\n",
    "df['right_context'] = df['right_context'].fillna('empty')\n",
    "\n",
    "df['concatenated'] = df['left_context'] + ' | ' + df['candidate_skill'] + ' | ' + df['right_context']\n",
    "print('Number of annotated rows ',df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import RegexpTokenizer\n",
    "def word2vec_vocab_check(text):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens =  tokenizer.tokenize(text)\n",
    "    try:\n",
    "        word2vec.wv[tokens]\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "#Function to retrieve word2vec vectors from spacy\n",
    "def word2vec_retriever_sum(text):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens =  tokenizer.tokenize(text)\n",
    "    wordvectors = sum(word2vec.wv[tokens])\n",
    "    return wordvectors\n",
    "    \n",
    "def word2vec_retriever_average(text):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens =  tokenizer.tokenize(text)\n",
    "    wordvectors = word2vec.wv[tokens]\n",
    "    average = sum(wordvectors)/len(wordvectors)\n",
    "    return average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20740 [00:00<?, ?it/s]<ipython-input-4-cd24b054c66e>:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  word2vec.wv[tokens]\n",
      "100%|██████████| 20740/20740 [00:00<00:00, 42088.18it/s]\n",
      "100%|██████████| 20740/20740 [00:00<00:00, 53557.57it/s]\n",
      "100%|██████████| 20740/20740 [00:00<00:00, 45956.55it/s]\n"
     ]
    }
   ],
   "source": [
    "#Removing out of vocabulary word2vec words\n",
    "df['vocab_check_left'] = df['left_context'].progress_apply(word2vec_vocab_check)\n",
    "df['vocab_check_middle'] = df['candidate_skill'].progress_apply(word2vec_vocab_check)\n",
    "df['vocab_check_right'] = df['right_context'].progress_apply(word2vec_vocab_check)\n",
    "df = df[(df.vocab_check_left==True) & (df.vocab_check_middle==True) & (df.vocab_check_right==True)]\n",
    "df = df.drop(columns=['vocab_check_left', 'vocab_check_middle', 'vocab_check_right'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/19253 [00:00<?, ?it/s]<ipython-input-4-cd24b054c66e>:21: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  wordvectors = word2vec.wv[tokens]\n",
      "100%|██████████| 19253/19253 [00:02<00:00, 7502.91it/s] \n",
      "100%|██████████| 19253/19253 [00:13<00:00, 1446.60it/s]\n",
      "100%|██████████| 19253/19253 [00:01<00:00, 13483.50it/s]\n",
      "100%|██████████| 19253/19253 [00:06<00:00, 2757.49it/s]\n",
      "100%|██████████| 19253/19253 [00:01<00:00, 15438.17it/s]\n",
      "100%|██████████| 19253/19253 [00:07<00:00, 2554.33it/s]\n"
     ]
    }
   ],
   "source": [
    "mode = word2vec_retriever_average\n",
    "#Retrieving the word2vec vectors\n",
    "x_left = pd.DataFrame(df['left_context'].progress_apply(mode))\n",
    "x_left = x_left['left_context'].progress_apply(pd.Series)\n",
    "\n",
    "#Retrieving the word2vec vectors\n",
    "x_right = pd.DataFrame(df['right_context'].progress_apply(mode))\n",
    "x_right = x_right['right_context'].progress_apply(pd.Series)\n",
    "\n",
    "#Retrieving the word2vec vectors\n",
    "x_middle = pd.DataFrame(df['candidate_skill'].progress_apply(mode))\n",
    "x_middle = x_middle['candidate_skill'].progress_apply(pd.Series)\n",
    "\n",
    "x = x_left\n",
    "x['sep'] = 222\n",
    "x = x.join(x_middle,lsuffix='_left', rsuffix='_middle')\n",
    "x['sep2'] = 222\n",
    "x = x.join(x_right,lsuffix='_middle', rsuffix='_right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model evaluation\n",
      "We are at classifier  LogisticRegression(max_iter=10000000000000000000000, random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 29.0min finished\n",
      " 17%|█▋        | 1/6 [29:00<2:25:04, 1740.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  GradientBoostingClassifier(learning_rate=1.0, max_depth=1, random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 47.9min finished\n",
      " 33%|███▎      | 2/6 [1:16:55<2:40:30, 2407.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  SGDClassifier(max_iter=10000000000000000000000, random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "/Users/ivowings/opt/anaconda3/envs/Thesis/lib/python3.8/site-packages/joblib/externals/loky/process_executor.py:688: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:   14.7s finished\n",
      " 50%|█████     | 3/6 [1:17:10<1:05:45, 1315.05s/it][Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  RandomForestClassifier(random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  5.3min finished\n",
      " 67%|██████▋   | 4/6 [1:22:27<30:42, 921.28s/it]   [Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  SVC(decision_function_shape='ovo', random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 13.0min finished\n",
      " 83%|████████▎ | 5/6 [1:35:27<14:30, 870.30s/it][Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  MLPClassifier(alpha=1e-05, hidden_layer_sizes=(15,),\n",
      "              max_iter=10000000000000000000000, random_state=456,\n",
      "              solver='lbfgs')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 62.4min finished\n",
      "100%|██████████| 6/6 [2:37:54<00:00, 1579.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 956 ms, sys: 2.63 s, total: 3.59 s\n",
      "Wall time: 2h 37min 54s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.724219</td>\n",
       "      <td>0.681418</td>\n",
       "      <td>0.686828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GBC</td>\n",
       "      <td>0.740304</td>\n",
       "      <td>0.586837</td>\n",
       "      <td>0.618528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.888826</td>\n",
       "      <td>0.705580</td>\n",
       "      <td>0.743193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.260427</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.292404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.696260</td>\n",
       "      <td>0.694736</td>\n",
       "      <td>0.681072</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier  Precision    Recall        F1\n",
       "0         LR   0.724219  0.681418  0.686828\n",
       "1        GBC   0.740304  0.586837  0.618528\n",
       "2        SGD        NaN       NaN       NaN\n",
       "3         RF   0.888826  0.705580  0.743193\n",
       "4        SVM   0.260427  0.333333  0.292404\n",
       "5        MLP   0.696260  0.694736  0.681072"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "y=df['label']\n",
    "functions.model_performance(x, df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19253/19253 [03:18<00:00, 96.78it/s] \n",
      "100%|██████████| 19253/19253 [03:35<00:00, 89.17it/s] \n",
      "100%|██████████| 19253/19253 [01:52<00:00, 170.68it/s]\n",
      "100%|██████████| 19253/19253 [01:53<00:00, 169.91it/s]\n"
     ]
    }
   ],
   "source": [
    "df['pos'] = df['candidate_skill'].progress_apply(functions.pos_tagger)\n",
    "df['pos'] = df['pos'].progress_apply(functions.sequence_counter)\n",
    "\n",
    "pos_dicts = df[['pos']]\n",
    "pos_dicts = pos_dicts['pos'].apply(pd.Series)\n",
    "pos_dicts = pos_dicts.fillna(0).astype(int)\n",
    "\n",
    "df['dep'] = df['candidate_skill'].progress_apply(functions.dep_tagger)\n",
    "df['dep'] = df['dep'].progress_apply(functions.sequence_counter)\n",
    "\n",
    "dep_dicts = df[['dep']]\n",
    "dep_dicts = dep_dicts['dep'].apply(pd.Series)\n",
    "dep_dicts = dep_dicts.fillna(0).astype(int)\n",
    "\n",
    "x_pos = pos_dicts.join(dep_dicts,lsuffix='_gram', rsuffix='_pos')\n",
    "\n",
    "x = x.join(x_pos, lsuffix='_embedding', rsuffix='_pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[x.isna().any(axis=1)].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model evaluation\n",
      "We are at classifier  LogisticRegression(max_iter=10000000000000000000000, random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 34.1min finished\n",
      " 17%|█▋        | 1/6 [34:08<2:50:41, 2048.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  GradientBoostingClassifier(learning_rate=1.0, max_depth=1, random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 35.6min finished\n",
      " 33%|███▎      | 2/6 [1:09:43<2:19:57, 2099.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  SGDClassifier(max_iter=10000000000000000000000, random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    5.0s finished\n",
      " 50%|█████     | 3/6 [1:09:48<57:09, 1143.16s/it]  [Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  RandomForestClassifier(random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  3.6min finished\n",
      " 67%|██████▋   | 4/6 [1:13:26<25:55, 777.77s/it] [Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  SVC(decision_function_shape='ovo', random_state=456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  9.0min finished\n",
      " 83%|████████▎ | 5/6 [1:22:24<11:31, 691.22s/it][Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are at classifier  MLPClassifier(alpha=1e-05, hidden_layer_sizes=(15,),\n",
      "              max_iter=10000000000000000000000, random_state=456,\n",
      "              solver='lbfgs')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed: 38.3min finished\n",
      "100%|██████████| 6/6 [2:00:45<00:00, 1207.52s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>0.728915</td>\n",
       "      <td>0.698318</td>\n",
       "      <td>0.696522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GBC</td>\n",
       "      <td>0.745919</td>\n",
       "      <td>0.585045</td>\n",
       "      <td>0.616304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>0.882573</td>\n",
       "      <td>0.704823</td>\n",
       "      <td>0.744965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.260427</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.292404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLP</td>\n",
       "      <td>0.699167</td>\n",
       "      <td>0.711972</td>\n",
       "      <td>0.690930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier  Precision    Recall        F1\n",
       "0         LR   0.728915  0.698318  0.696522\n",
       "1        GBC   0.745919  0.585045  0.616304\n",
       "2        SGD        NaN       NaN       NaN\n",
       "3         RF   0.882573  0.704823  0.744965\n",
       "4        SVM   0.260427  0.333333  0.292404\n",
       "5        MLP   0.699167  0.711972  0.690930"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functions.model_performance(x, df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
