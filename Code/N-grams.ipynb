{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from flashtext import KeywordProcessor\n",
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "import sys\n",
    "import re\n",
    "\n",
    "#progress bar packages\n",
    "from tqdm import tqdm\n",
    "#ngram package\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import nltk\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#for downloading spacy stuff\n",
    "#!{sys.executable} -m spacy download en\n",
    "\n",
    "#en is the large model\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 302284/302284 [00:26<00:00, 11533.63it/s]\n",
      "  0%|          | 0/28709 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16433802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28709/28709 [00:00<00:00, 36643.50it/s]\n",
      "100%|██████████| 16433802/16433802 [02:57<00:00, 92801.19it/s] \n",
      "<ipython-input-4-2f4ebe647bc9>:62: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  allgrams['allgrams'] = allgrams['allgrams'].str.replace(r\"[(),.']\", '')\n"
     ]
    }
   ],
   "source": [
    "df_sentences = pd.read_csv(\"/Users/ivowings/Sync/Thesis/Datasources/Preprocessed/sentences/sentences_emscad.csv\")\n",
    "df_softskills = pd.read_csv(\"/Users/ivowings/Sync/Thesis/Datasources/Preprocessed/Skills/softskills.csv\")\n",
    "df_hardskills = pd.read_csv(\"/Users/ivowings/Sync/Thesis/Datasources/Preprocessed/Skills/emsi_skills.csv\")\n",
    "\n",
    "df_hardskills = df_hardskills[df_hardskills['type']== 'Hard Skill']\n",
    "df_hardskills = pd.DataFrame(df_hardskills['name'])\n",
    "\n",
    "#soft_skill,soft_skill_lemmatized,soft_skill_no_stopwords\n",
    "columnname = 'soft_skill_lemmatized'\n",
    "df_softskills = df_softskills[[columnname]]\n",
    "\n",
    "#Renameing the skill column names and merging afterwards\n",
    "df_softskills = df_softskills.rename(columns={columnname: 'skill'})\n",
    "df_hardskills = df_hardskills.rename(columns={'name': 'skill'})\n",
    "df_skills = pd.concat([df_softskills, df_hardskills])\n",
    "df_skills = df_skills.drop_duplicates()\n",
    "df_skills\n",
    "\n",
    "#Creating all the possible grams for each sentence\n",
    "allgrams = []\n",
    "\n",
    "#This tokenizer immediately removes punctuation and special characters from the sentence\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "#,sentence,sentence_lemmatized,sentence_no_stopwords\n",
    "\n",
    "for sentence in tqdm(df_sentences['sentence_lemmatized']):\n",
    "    tokenizedsentence = tokenizer.tokenize(str(sentence))\n",
    "    \n",
    "    #Getting all possible n grams of the sentence\n",
    "    #for n in range(1,len(tokenizedsentence)+1):\n",
    "    \n",
    "    #getting up to four grams for each sentence\n",
    "    for n in range(1,5):\n",
    "        grams = ngrams(tokenizedsentence,n)\n",
    "        for gram in grams:\n",
    "            allgrams.append(str(gram))\n",
    "\n",
    "allgrams = pd.DataFrame(allgrams)\n",
    "allgrams = allgrams.rename(columns={0:'allgrams'})\n",
    "print(allgrams.shape[0])\n",
    "\n",
    "#Initializing the keyword processor\n",
    "keyword_processor = KeywordProcessor(case_sensitive=False)\n",
    "\n",
    "#Adding all the skills to the processor\n",
    "for skill in tqdm(df_skills['skill']):\n",
    "    keyword_processor.add_keyword(skill)\n",
    "\n",
    "def searcher(row):\n",
    "    #check if the words are in the row and return a True or False instead of the actual word\n",
    "    boolean = bool(keyword_processor.extract_keywords(row))\n",
    "    return boolean\n",
    "\n",
    "tqdm.pandas()\n",
    "allgrams['contains_skill'] = allgrams['allgrams'].progress_apply(searcher)\n",
    "\n",
    "#Only selecting the ngrams which contain a skill\n",
    "allgrams = allgrams[allgrams.contains_skill == True]\n",
    "#cleaning up\n",
    "allgrams['allgrams'] = allgrams['allgrams'].astype(str)\n",
    "allgrams['allgrams'] = allgrams['allgrams'].str.replace(r\"[(),.']\", '')\n",
    "allgrams['allgrams'] = allgrams['allgrams'].str.strip()\n",
    "allgrams = allgrams.drop(columns=['contains_skill'])\n",
    "\n",
    "#Some softskills match multiple times, therefore removing the duplicates\n",
    "allgrams = allgrams.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "#removing any nans\n",
    "allgrams.dropna(subset=['allgrams'],inplace=True)\n",
    "\n",
    "import csv\n",
    "allgrams.to_csv(\"/Users/ivowings/Sync/Thesis/Datasources/Preprocessed/Combined/Taxonomy/Lemmatized/n-grams.csv\", quoting=csv.QUOTE_NONNUMERIC, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 302284/302284 [00:14<00:00, 21058.62it/s]\n",
      " 24%|██▎       | 6786/28709 [00:00<00:00, 67854.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12758752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28709/28709 [00:00<00:00, 71503.51it/s]\n",
      "100%|██████████| 12758752/12758752 [01:35<00:00, 132970.81it/s]\n",
      "<ipython-input-3-df972771df2a>:62: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  allgrams['allgrams'] = allgrams['allgrams'].str.replace(r\"[(),.']\", '')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>allgrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>team</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>small team</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>team of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a small team</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>small team of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308888</th>\n",
       "      <td>creatively and step</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308889</th>\n",
       "      <td>figure problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308890</th>\n",
       "      <td>to figure problem</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308891</th>\n",
       "      <td>figure problem out</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308892</th>\n",
       "      <td>problem out on</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>308893 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   allgrams\n",
       "0                      team\n",
       "1                small team\n",
       "2                   team of\n",
       "3              a small team\n",
       "4             small team of\n",
       "...                     ...\n",
       "308888  creatively and step\n",
       "308889       figure problem\n",
       "308890    to figure problem\n",
       "308891   figure problem out\n",
       "308892       problem out on\n",
       "\n",
       "[308893 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentences = pd.read_csv(\"/Users/ivowings/Sync/Thesis/Datasources/Preprocessed/sentences/sentences_emscad.csv\")\n",
    "df_softskills = pd.read_csv(\"/Users/ivowings/Sync/Thesis/Datasources/Preprocessed/Skills/softskills.csv\")\n",
    "df_hardskills = pd.read_csv(\"/Users/ivowings/Sync/Thesis/Datasources/Preprocessed/Skills/emsi_skills.csv\")\n",
    "\n",
    "df_hardskills = df_hardskills[df_hardskills['type']== 'Hard Skill']\n",
    "df_hardskills = pd.DataFrame(df_hardskills['name'])\n",
    "\n",
    "#soft_skill,soft_skill_lemmatized,soft_skill_no_stopwords\n",
    "columnname = 'soft_skill_lemmatized'\n",
    "df_softskills = df_softskills[[columnname]]\n",
    "\n",
    "#Renameing the skill column names and merging afterwards\n",
    "df_softskills = df_softskills.rename(columns={columnname: 'skill'})\n",
    "df_hardskills = df_hardskills.rename(columns={'name': 'skill'})\n",
    "df_skills = pd.concat([df_softskills, df_hardskills])\n",
    "df_skills = df_skills.drop_duplicates()\n",
    "df_skills\n",
    "\n",
    "#Creating all the possible grams for each sentence\n",
    "allgrams = []\n",
    "\n",
    "#This tokenizer immediately removes punctuation and special characters from the sentence\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "#,sentence,sentence_lemmatized,sentence_no_stopwords\n",
    "\n",
    "for sentence in tqdm(df_sentences['sentence_lemmatized']):\n",
    "    tokenizedsentence = tokenizer.tokenize(str(sentence))\n",
    "    \n",
    "    #Getting all possible n grams of the sentence\n",
    "    #for n in range(1,len(tokenizedsentence)+1):\n",
    "    \n",
    "    #getting up to tri grams for each sentence\n",
    "    for n in range(1,4):\n",
    "        grams = ngrams(tokenizedsentence,n)\n",
    "        for gram in grams:\n",
    "            allgrams.append(str(gram))\n",
    "\n",
    "allgrams = pd.DataFrame(allgrams)\n",
    "allgrams = allgrams.rename(columns={0:'allgrams'})\n",
    "print(allgrams.shape[0])\n",
    "\n",
    "#Initializing the keyword processor\n",
    "keyword_processor = KeywordProcessor(case_sensitive=False)\n",
    "\n",
    "#Adding all the skills to the processor\n",
    "for skill in tqdm(df_skills['skill']):\n",
    "    keyword_processor.add_keyword(skill)\n",
    "\n",
    "def searcher(row):\n",
    "    #check if the words are in the row and return a True or False instead of the actual word\n",
    "    boolean = bool(keyword_processor.extract_keywords(row))\n",
    "    return boolean\n",
    "\n",
    "tqdm.pandas()\n",
    "allgrams['contains_skill'] = allgrams['allgrams'].progress_apply(searcher)\n",
    "\n",
    "#Only selecting the ngrams which contain a skill\n",
    "allgrams = allgrams[allgrams.contains_skill == True]\n",
    "#cleaning up\n",
    "allgrams['allgrams'] = allgrams['allgrams'].astype(str)\n",
    "allgrams['allgrams'] = allgrams['allgrams'].str.replace(r\"[(),.']\", '')\n",
    "allgrams['allgrams'] = allgrams['allgrams'].str.strip()\n",
    "allgrams = allgrams.drop(columns=['contains_skill'])\n",
    "\n",
    "#Some softskills match multiple times, therefore removing the duplicates\n",
    "allgrams = allgrams.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "#removing any nans\n",
    "allgrams.dropna(subset=['allgrams'],inplace=True)\n",
    "\n",
    "allgrams.to_csv(\"/Users/ivowings/Sync/Thesis/Datasources/Preprocessed/n-grams/emscad_trigrams_lemmatized_taxonomy.csv\", quoting=csv.QUOTE_NONNUMERIC,index=False)\n",
    "allgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 302284/302284 [00:09<00:00, 33309.48it/s]\n",
      " 32%|███▏      | 9185/28860 [00:00<00:00, 91846.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7607899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28860/28860 [00:00<00:00, 83557.24it/s]\n",
      "100%|██████████| 7607899/7607899 [01:03<00:00, 120493.54it/s]\n",
      "<ipython-input-4-fa3654302a36>:62: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  allgrams['allgrams'] = allgrams['allgrams'].str.replace(r\"[(),.']\", '')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>allgrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>team</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>small team</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>team editors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>work small team</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>small team editors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406592</th>\n",
       "      <td>think creatively step</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406593</th>\n",
       "      <td>creatively step outside</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406594</th>\n",
       "      <td>eager learn great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406595</th>\n",
       "      <td>figure problems</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406596</th>\n",
       "      <td>able figure problems</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>406597 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       allgrams\n",
       "0                          team\n",
       "1                    small team\n",
       "2                  team editors\n",
       "3               work small team\n",
       "4            small team editors\n",
       "...                         ...\n",
       "406592    think creatively step\n",
       "406593  creatively step outside\n",
       "406594        eager learn great\n",
       "406595          figure problems\n",
       "406596     able figure problems\n",
       "\n",
       "[406597 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentences = pd.read_csv(\"/Users/ivowings/Sync/Thesis/Datasources/Preprocessed/sentences/sentences_emscad.csv\")\n",
    "df_softskills = pd.read_csv(\"/Users/ivowings/Sync/Thesis/Datasources/Preprocessed/Skills/softskills.csv\")\n",
    "df_hardskills = pd.read_csv(\"/Users/ivowings/Sync/Thesis/Datasources/Preprocessed/Skills/emsi_skills.csv\")\n",
    "\n",
    "df_hardskills = df_hardskills[df_hardskills['type']== 'Hard Skill']\n",
    "df_hardskills = pd.DataFrame(df_hardskills['name'])\n",
    "\n",
    "#soft_skill,soft_skill_lemmatized,soft_skill_no_stopwords\n",
    "columnname = 'soft_skill_no_stopwords'\n",
    "df_softskills = df_softskills[[columnname]]\n",
    "\n",
    "#Renameing the skill column names and merging afterwards\n",
    "df_softskills = df_softskills.rename(columns={columnname: 'skill'})\n",
    "df_hardskills = df_hardskills.rename(columns={'name': 'skill'})\n",
    "df_skills = pd.concat([df_softskills, df_hardskills])\n",
    "df_skills = df_skills.drop_duplicates()\n",
    "df_skills\n",
    "\n",
    "#Creating all the possible grams for each sentence\n",
    "allgrams = []\n",
    "\n",
    "#This tokenizer immediately removes punctuation and special characters from the sentence\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "#,sentence,sentence_lemmatized,sentence_no_stopwords\n",
    "\n",
    "for sentence in tqdm(df_sentences['sentence_no_stopwords']):\n",
    "    tokenizedsentence = tokenizer.tokenize(str(sentence))\n",
    "    \n",
    "    #Getting all possible n grams of the sentence\n",
    "    #for n in range(1,len(tokenizedsentence)+1):\n",
    "    \n",
    "    #getting up to tri grams for each sentence\n",
    "    for n in range(1,4):\n",
    "        grams = ngrams(tokenizedsentence,n)\n",
    "        for gram in grams:\n",
    "            allgrams.append(str(gram))\n",
    "\n",
    "allgrams = pd.DataFrame(allgrams)\n",
    "allgrams = allgrams.rename(columns={0:'allgrams'})\n",
    "print(allgrams.shape[0])\n",
    "\n",
    "#Initializing the keyword processor\n",
    "keyword_processor = KeywordProcessor(case_sensitive=False)\n",
    "\n",
    "#Adding all the skills to the processor\n",
    "for skill in tqdm(df_skills['skill']):\n",
    "    keyword_processor.add_keyword(skill)\n",
    "\n",
    "def searcher(row):\n",
    "    #check if the words are in the row and return a True or False instead of the actual word\n",
    "    boolean = bool(keyword_processor.extract_keywords(row))\n",
    "    return boolean\n",
    "\n",
    "tqdm.pandas()\n",
    "allgrams['contains_skill'] = allgrams['allgrams'].progress_apply(searcher)\n",
    "\n",
    "#Only selecting the ngrams which contain a skill\n",
    "allgrams = allgrams[allgrams.contains_skill == True]\n",
    "#cleaning up\n",
    "allgrams['allgrams'] = allgrams['allgrams'].astype(str)\n",
    "allgrams['allgrams'] = allgrams['allgrams'].str.replace(r\"[(),.']\", '')\n",
    "allgrams['allgrams'] = allgrams['allgrams'].str.strip()\n",
    "allgrams = allgrams.drop(columns=['contains_skill'])\n",
    "\n",
    "#Some softskills match multiple times, therefore removing the duplicates\n",
    "allgrams = allgrams.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "#removing any nans\n",
    "allgrams.dropna(subset=['allgrams'],inplace=True)\n",
    "\n",
    "allgrams.to_csv(\"/Users/ivowings/Sync/Thesis/Datasources/Preprocessed/n-grams/emscad_trigrams_nostopwords_taxonomy.csv\", quoting=csv.QUOTE_NONNUMERIC,index=False)\n",
    "allgrams"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
