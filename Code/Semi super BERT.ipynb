{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    " \n",
    "import thesis_helper\n",
    "functions = thesis_helper.Thesis_Helper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            0\n",
      "0    0.632630\n",
      "1    0.764681\n",
      "2    0.402446\n",
      "3    0.208359\n",
      "4    1.442075\n",
      "..        ...\n",
      "763 -0.123011\n",
      "764 -0.119338\n",
      "765  0.098385\n",
      "766 -0.323263\n",
      "767 -0.925233\n",
      "\n",
      "[768 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(sentence[0].embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Token: 1 grass"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_context = \"/Users/ivowings/Sync/Thesis/Datasources/Preprocessed/n-grams context/Annotated/sentence_trigrams_context_excelsubset.csv\"\n",
    "path_context2 = \"/Users/ivowings/Sync/Thesis/Datasources/Preprocessed/n-grams context/Annotated/sentence_trigrams_context_excelsubset2.csv\"\n",
    "path_trigrams = \"/Users/ivowings/Sync/Thesis/Datasources/Preprocessed/n-grams/Annotated/emscad_trigrams_taxonomy.csv\"\n",
    "\n",
    "path_trigrams_lemmatized = \"/Users/ivowings/Sync/Thesis/Datasources/Preprocessed/n-grams/Annotated/emscad_trigrams_lemmatized_taxonomy.csv\"\n",
    "path_context_lemmatized = \"/Users/ivowings/Sync/Thesis/Datasources/Preprocessed/n-grams context/Annotated/sentence_trigrams_context_lemmatized.csv\"\n",
    "\n",
    "pre_annotated__softskills = '/Users/ivowings/Sync/Thesis/Datasources/Skills/Pre annotated soft skills/annotated_soft_skills.csv'\n",
    "\n",
    "gazette = '/Users/ivowings/Desktop/gazette.csv'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_context = functions.load_context_df(path_context,';')\n",
    "df_context2 = functions.load_context_df(path_context2,';')\n",
    "\n",
    "df_trigrams = pd.read_csv(path_trigrams, sep=';')\n",
    "\n",
    "df_preannotated = pd.read_csv(pre_annotated__softskills)\n",
    "\n",
    "df_gazette = pd.read_csv(gazette)\n",
    "\n",
    "df = pd.concat([df_gazette,\n",
    "                df_preannotated,\n",
    "                df_trigrams,\n",
    "                df_context,\n",
    "                df_context2\n",
    "               ]).reset_index(drop=True)\n",
    "\n",
    "df = df.drop(columns=['length']).sort_values(by=['label'])\n",
    "#Replacing missing labels with -1\n",
    "df['label'] = df['label'].fillna(-1).astype(int)\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "df = df.head(100000)\n",
    "print('Number of annotated rows ',df.shape[0])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_embeddings_allgrams=pd.DataFrame(df['allgrams'].progress_apply(bert_embedder))\n",
    "bert_embeddings_allgrams = bert_embeddings_allgrams[0].apply(pd.Series)\n",
    "\n",
    "x = bert_embeddings_allgrams\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['pos'] = df['allgrams'].progress_apply(functions.pos_tagger)\n",
    "# df['pos'] = df['pos'].progress_apply(functions.sequence_counter)\n",
    "\n",
    "# pos_dicts = df[['pos']]\n",
    "# pos_dicts = pos_dicts['pos'].apply(pd.Series)\n",
    "# pos_dicts = pos_dicts.fillna(0).astype(int)\n",
    "\n",
    "# df['dep'] = df['allgrams'].progress_apply(functions.dep_tagger)\n",
    "# df['dep'] = df['dep'].progress_apply(functions.sequence_counter)\n",
    "\n",
    "# dep_dicts = df[['dep']]\n",
    "# dep_dicts = dep_dicts['dep'].apply(pd.Series)\n",
    "# dep_dicts = dep_dicts.fillna(0).astype(int)\n",
    "\n",
    "\n",
    "# x = x.join(pos_dicts,lsuffix='_gram', rsuffix='_pos')\n",
    "# x = x.join(dep_dicts,lsuffix='_pos', rsuffix='_dep')\n",
    "\n",
    "# y = df['label'].fillna(-1).astype(int)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# x = functions.load_object('semi_super_BERT_pos_x')\n",
    "# y = functions.load_object('semi_super_BERT_pos_y')\n",
    "                                                        \n",
    "\n",
    "# x_nopos = x.iloc[:, [x for x in range(0,768)]]\n",
    "# #removing the pos columns\n",
    "y = df['label']\n",
    "\n",
    "\n",
    "from sklearn.semi_supervised import SelfTrainingClassifier\n",
    "\n",
    "semi_super_BERT_LR_wgazette = SelfTrainingClassifier(functions.LR,verbose=True, threshold=0.99,max_iter=10)\n",
    "semi_super_BERT_LR_wgazette.fit(x, y)\n",
    "\n",
    "functions.store_object('semi_super_BERT_LR_wgazette',semi_super_BERT_LR_wgazette)\n",
    "\n",
    "# semi_super_BERT_ANN_nopos = SelfTrainingClassifier(functions.ANN,verbose=True, threshold=0.99,max_iter=10)\n",
    "# semi_super_BERT_ANN_nopos.fit(x_nopos, y), \n",
    "\n",
    "\n",
    "\n",
    "# functions.store_object('semi_super_BERT_ANN_nopos',semi_super_BERT_ANN_nopos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions.store_object('x_wgazette',x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
